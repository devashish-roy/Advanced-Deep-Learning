## Brief description of each labs:
- Lab0 - Train CNN, Experiment with Stochastic gradient descent (SGD) and Adam as the optimizer, activation as Tanh and LeakyReLU. Use of Tensorboard to Visualize the results. Transfer Learning from ImageNet to AlexNet on CIFAR-10 data, Transfer Learning from MNIST to SVHN dataset. Use of PyTorch framework.
- Lab1 - Created a simple chatbot that analyzes text responses typed by a user using an artificial neural network (ANN). Implemented transformer by following Andrej Karpathy tutorial for a NanoGPT "https://www.youtube.com/watch?v=kCc8FmEb1nY" and use his GitHub code "https://github.com/karpathy/nanoGPT?tab=readme-ov-file". And compared teh results fof both the implementations.
- Lab2 - Implement a Vanilla GAN as described by Goodfellow in his paper "https://arxiv.org/abs/1406.2661" to generate adversarial MNIST images. Implement conditional GAN so as to generate MNIST image of own choice (provide the number in input). Create adversarial images to fool a MNIST classifier as per paper by Jasoni Carter "https://github.com/jasonicarter/MNIST-adversarial-images".
- Lab4 - Handson with Algorithm "DQN with Experience Replay" published by Deepmind 2013 https://arxiv.org/pdf/1312.5602v1 where they showed that a reinforcement learning algorithm can learn how to play many different Atari games completely on its own with only the pixel values as input. Most of the code was already provided. Our task was just to fix some missing part of the code and make it work (code + environnment) and train the model and observe how the model learns with the progress of epochs.
